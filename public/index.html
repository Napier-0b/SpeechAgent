<!DOCTYPE html>
<html lang="jp">
<head>
    <meta charset="UTF-8">
    <title>Speech-Text-Synthesis</title>
	<script>
 
	// 利用するWebAPIをインスタンス化する
	window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
	const recog = new SpeechRecognition();
	const synth = new SpeechSynthesisUtterance();	
	
	const defaultInput = "";
	let input = defaultInput;
 
 
	// 聞き取り中に、マイクからの入力があったときのイベント
	recog.addEventListener("result", e => {
 
		// 入力結果をテキストで取得し、それをグローバル変数に格納し、聞き取りを終了する
		input = e.results[0][0].transcript;
		recog.stop();
	});
 
	// 聞き取りを終了したときのイベント
	recog.addEventListener("end", () => {
 
		// 入力結果が初期状態の場合は聞き取りが自動終了したと判断し、聞き取りを再開する
		if (input === defaultInput) {
			recog.start();
		}
		// 入力結果に値があればそれを読み上げ、入力結果を初期化する
		else {
			synth.text = input;
			document.querySelector("#recognizedText").textContent = input;
			input= defaultInput;
			speechSynthesis.speak(synth);
		}
	});
 
	// 読み上げを終了したときのイベント
	synth.addEventListener("end", () => {
 
		// 聞き取りを再開する
		recog.start();
	});
 
	// 聞き取りを開始する
	recog.start();
 
</script>
</head>
<body>
マイクに話した内容を認識し、発話が終了すると以下に表示したうえで読み上げます。<br>
ちょっとした声も全部拾って読み上げてしまうので、喋りたい時だけマイクのスイッチをオンにすることをおすすめします。<br>
<br>
認識内容：<div id="recognizedText"></div><br>
<img src="floatingBadland96748.png" alt="FloatingBadland96748"><br>
How to use it in VRChat?: <a href="https://qiita.com/Napier-JP/items/a22dfabbca8bc37eac34#netduetto%E3%81%AE%E6%BA%96%E5%82%99">Qiita guide</a><br>
Contact: <a href="https://twitter.com/Napier_SunPro">@Napier_SunPro</a> (Notlob on VRChat)
</body>
</html>